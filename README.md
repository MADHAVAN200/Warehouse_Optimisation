# Walmart OptiFresh: AI-driven Freshness Assurance & Dynamic Rebalancer for Walmart

## 1. Strategic Fit & Business Value

Walmart has set aggressive 2025–2030 sustainability targets: for example, a goal to cut Scope 1+2 GHG emissions 35% by 2025 and 65% by 2030 (vs. 2015), and to halve its operational food waste by 2030 (vs. 2016).  Its new **Grow with US** initiative provides U.S. entrepreneurs (now 60% of Walmart’s US suppliers) with training, mentorship and financial support.  An automated freshness-scoring engine directly advances all these goals: by proactively identifying at-risk perishables, it reduces waste and the associated emissions, while boosting sales and supporting small suppliers.  For instance, real-time freshness tracking enables timely markdowns or inter-store transfers so that produce never spoils on the shelf. Studies show that retailers optimizing supply–demand balance can cut markdown/spoilage costs by up to \~30%, and dynamic pricing alone could slash grocery waste by \~21%. At Walmart’s scale, even a 10% drop in perishables spoilage is huge: U.S. grocery stores generated \~4.45 M tons of surplus food in 2023 (15.4% of that was spoiled), so a 10% spoilage reduction would recover ~~684k tons~~ worth of food that can be sold instead of wasted. Timely “flash sales” on soon-to-expire items turns potential waste into incremental revenue.  Meanwhile, tamper-proof Freshness Reports (via blockchain) create an immutable audit trail of temperature and handling data – boosting consumer trust and protecting Walmart against legal/FSMA compliance risks by proving due diligence in handling perishables.

**Quantified impact:**  Conservatively, if Walmart’s fresh category is on the order of \$10–20 B/yr, preventing even 5% of spoilage would recoup hundreds of millions in value.  A 20% uplift in flash-sale velocity could contribute tens of millions in incremental margin.  Reducing waste also lowers indirect GHG (less landfill methane, fewer unnecessary deliveries).  Thus, the AI freshness engine both accelerates waste/GHG targets and ties into Walmart’s “Grow with US” effort by giving smaller produce vendors the tools to sell more of their harvest.

## 2. API Integration Blueprint

We will leverage Walmart’s existing APIs to automate data flows across the fresh supply chain.  Key endpoints and flows include:

* **Inbound Condition Monitoring:** Use the **WFS Inbound Preview API** (e.g. `POST /v3/fulfillment/inbound-preview`) to fetch upcoming inbound shipment plans and expected SKUs.  As shipments arrive at distribution centers, poll the **Inventory Log API** (`GET /v3/fulfillment/inventory-log`) to retrieve timestamped events for each item (e.g. arrival scans, rejection notes).  For Drop-Ship Vendors (1P suppliers), use the Supplier **Inbound Shipments** and **Inventory APIs**: e.g. `GET /v3/shipments` to list pending shipments and `GET /v1/inventory` for current on-hand at each node.  These endpoints feed real-time condition data (e.g. whether a load was held up or delayed), which the freshness engine ingests.

* **Real-Time Freshness Scoring:**  Integrate the **DSV Lag Time API** (`GET /v1/lag-time`) to obtain up-to-date lead times for Drop-Ship Vendor routes.  Combine this with external weather/temperature data (e.g. NOAA or a cloud weather API) and IoT sensor streams.  For example, we cross-reference the shipment’s planned transit days with forecasted temperatures: longer lag + higher heat = higher spoilage risk.  We also pull each batch’s baseline shelf-life (from item metadata).  The ML model outputs a freshness score for every perishable SKU instance, updated in real time as conditions change.

* **Dynamic Markdowns:**  To liquidate items flagged as high-risk, we use Walmart’s **Feeds API** for bulk price changes.  Specifically, we can submit a Pricing Feed (via `POST /v3/feeds?type=PriceFeed`) containing markdown prices or promotional rules for selected SKUs, and then poll `GET /v3/feeds/{feedId}/status` to confirm application.  We also leverage the **Real-Time Pricing & Availability API** (`GET /v1/pricingavailability`) to fetch current price and stock for a given SKU at a target store, ensuring our markdown is competitive.  In practice, the system might trigger a tiered discount (e.g. –20% at 3 days from expiry, –50% at 1 day) by updating a price list via the Feeds API.

* **Inter-Store Transfers:**  Our service will detect when one store’s surplus can offset another store’s shortage before spoilage.  We use the **Marketplace Inventory API** (`GET /v3/inventory`) to retrieve on-hand quantities of a SKU across all store nodes.  If Store A has near-expiry stock while Store B has demand, the engine issues an internal transfer: create a “Customer Order” via the **Orders API** (e.g. `POST /v3/orders` for a simplified transfer order) specifying the source and destination stores.  Once routed, we update the Inventory API (`PUT /v3/inventory`) to reflect the movement.  This redistributes fresh goods where needed.

* **Customer Transparency Badges:**  To surface freshness info to shoppers, we use the **Item Management API**. For example, we can update an item’s listing via `PUT /v3/items` to include a “Certified Fresh” badge or freshness-dating text in the product description.  Bulk item edits (e.g. tagging 100 SKUs as “expires in 3 days”) can be done with the **Bulk Item Setup (Multiple)** endpoint.  These badges are read by the Walmart web/mobile front end to show badges like “Freshness Assured” on eligible products.

**Auth & Scale:** All Walmart Marketplace/1P APIs use OAuth 2.0 (Client ID/Secret) to obtain bearer tokens for each call.  We will set up separate sandbox credentials for testing vs. production.  To handle large volumes (thousands of SKUs), we favor bulk operations: e.g. use the Feeds API or bulk-inventory endpoints rather than looping single-item calls.  For example, the **Bulk Item Inventory Update** endpoint can update stock for 10,000 SKUs in one feed.  Single-SKU calls (GET/PUT) are used for real-time small updates or checks.  We’ll implement asynchronous job orchestration (e.g. queue SKU chunks, monitor feed status) to stay within API rate limits while achieving throughput.

## 3. State-of-the-Art AI & Open-Source Tooling

For spoilage-risk forecasting, we recommend a **Temporal Fusion Transformer (TFT)** model.  TFT is a deep sequence-to-sequence architecture designed for multi-horizon time series forecasting, capable of ingesting static metadata (SKU category, average shelf-life), past covariates (recent sales, historical spoilage) and known future inputs (predicted weather, transit days).  TFT has been shown to outperform LSTM/GRU baselines on complex forecasting tasks.  We will train it on features such as time index, historical demand, inbound lag time, temperature/humidity history, and calendar effects.  For training, we will leverage GPUs (e.g. PyTorch Lightning on Azure/AWS instances) and scale with frameworks like Kubeflow or SageMaker.  TensorFlow or PyTorch (via PyTorch Forecasting) are suitable platforms.

For decision optimization (markdown vs transfer), we propose a reinforcement-learning (RL) framework.  The **state** includes inventory levels, current freshness scores, and demand forecasts; **actions** include “mark down 10%/20%”, “do nothing”, or “transfer X units to store Y”.  The **reward** could be defined as profit (sales minus waste) or a weighted sum of margin and waste penalties.  We can implement this using open-source libraries like **Ray RLlib** or **Stable Baselines3**.  For example, a PPO agent can be trained in a simulated environment (using historical demand traces) to learn optimal timing of markdowns vs transfers.  As a simple POC fallback, a rule-based policy might be: “If freshness score <10% (nearly expired), immediately do a 50% markdown; if multiple stores have >30% demand and one has excess stock, split a transfer order evenly.”

Our data and ML stack will rely on proven open-source tools.  Use **Delta Lake** on Databricks (on GCP or Azure) for time-series storage with ACID and versioning.  Build data pipelines with **Kubeflow Pipelines** (or ZenML) to preprocess IoT sensor streams and join with sales/inventory data.  Models will be developed in **PyTorch** or **TensorFlow**; we can use Facebook Prophet as a simple benchmark for seasonal demand.  For MLOps, we’ll use model versioning and serving frameworks (e.g. MLflow or TensorFlow Serving).  Continuous training and deployment can be orchestrated with Kubeflow or tools like **ArgoCD**, integrating with Walmart’s Azure/GCP infrastructure.  Monitoring can use Prometheus/Grafana or Azure Monitor to track model performance and data drifts.

## 4. Blockchain Architecture

For immutable Freshness Reports, a private permissioned ledger is best.  **Hyperledger Fabric** is a strong fit: it is already proven in Walmart’s supply chain context (the IBM Food Trust initiative), offers fine-grained permissioning, and supports high throughput in private networks.  We would implement a Fabric network with chaincode (smart contracts) to log temperature and transfer events.  For example, define a chaincode “ShipmentLedger” with functions like `recordTempReading(shipmentID, timestamp, temperature)` and `recordTransfer(skuID, fromStore, toStore, qty, timestamp)`.  Endorsement policies ensure only Walmart and authorized supplier peers can submit or read data.  The network topology might include peers at Walmart HQ/DC and at major suppliers, with a RAFT ordering service cluster to commit blocks.  We’d use channels or private data collections to restrict visibility if needed (e.g. one channel for leafy greens suppliers).

Alternatively, **Hyperledger Sawtooth** could be considered (it uses a PoET consensus which is lightweight), but Fabric’s richer privacy (channels, ACLs) and Walmart’s experience with IBM make it preferable.  **Hyperledger Besu** (permissioned Ethereum) is another option if we wanted to leverage Solidity smart contracts, but it adds gas-model complexity and is less battle-tested in retail.  We lean Fabric for consistency with Walmart’s existing blockchain pilots.

Integration: The freshness microservices will invoke Fabric SDK calls whenever an event occurs.  For example, when a trailer’s IoT device logs a high temperature, our service calls `recordTempReading` on Fabric (via gRPC/REST gateway).  We can also emit Fabric block events back into our analytics (e.g. via Kafka) to sync ledger data into Walmart’s ERP or data lake.  To interface with Walmart’s ERP/TMS (e.g. SAP), we can build a middleware layer: either have ERP systems poll the Fabric REST API for a given shipment’s record, or push Fabric events to the ERP via webhooks/ETL.

**Performance & Security:** Fabric (or Sawtooth) can handle several hundred transactions per second in a moderate cluster, which is adequate since we only record key events (we can batch readings if needed).  Data is cryptographically secured – any tampering with historical freshness logs is infeasible.  Using a permissioned chain also protects business data.  Compared to a public chain, this yields higher throughput and control.  The tradeoff is complexity: we must maintain node infrastructure and governance.  But this yields an indelible audit trail (for regulatory compliance) and aligns with Walmart’s stated blockchain traceability initiatives.

## 5. Success Metrics & Dashboard

We will validate the system in realistic test scenarios.  For example, a *cold-chain breach* test: simulate a shipment with a temperature spike, and verify the system flags it (freshness score drops) and logs the breach on-chain.  A *high-velocity rebalancing* test: simulate sudden demand at Store B, and ensure the engine moves goods from Store A in time.  A *badge validation* test: a customer taps a fresh item’s QR code and sees live freshness info pulled from our system.

**Success criteria:** Quantitatively, we target measurable improvements.  For spoilage, a key metric could be “% perishable shrink reduced” (e.g. −10–20%).  For sales, “incremental revenue from flash sales” (e.g. +\$XM/month).  We will measure system health: API latency should meet SLAs (e.g. ≥99.9% calls <200ms), and blockchain reports should capture ≥99% of eligible events.  Auditability: 100% of transported perishables should have a Freshness Report entry.

We propose a live dashboard (e.g. Grafana/PowerBI) showing: spoilage tons prevented, revenue recovered via markdowns, average freshness score over time, number of transfers executed, API call success rates, and chain ledger stats (records logged vs expected).  For example, one panel might track “average spoilage %” by category month-over-month, another shows “marks down vs sales” performance.  High-level KPIs (waste reduction %, sales uplift %) give executives a quick view of project ROI.

## 6. Risk Assessment & Mitigation

**Technical risks:** IoT sensors can drift or fail.  Mitigation: use calibrated sensors, perform regular validation (e.g. cross-check with reference sensors), and fall back to manual sampling if anomalies occur.  API limits could throttle calls; mitigate by using bulk feeds and exponential backoff, caching non-critical data, and securing elevated quotas.  Data integration bugs (e.g. mapping wrong SKU) can be caught with rigorous testing and monitoring.

**Operational/legal risks:** Consumer protection laws (FTC) frown on deceptive freshness claims.  We must ensure badges only reflect certified data (no subjective claims).  All freshness estimates must comply with FSMA traceability rules and FDA standards for labeling.  We’ll consult legal to align on what “Freshness Guarantee” language is allowable.  Supply chain disruption (e.g. a new farm technology) will require updating models and retraining.

**Blockchain governance:** Permissioned chain requires clear management.  We’ll form a consortium committee (Walmart + top suppliers) to oversee policies.  For security, all chain nodes use strong identity certificates and channels.  Performance: to avoid bottlenecks, we’ll batch temperature logs (e.g. one entry per batch).  Privacy: use Fabric’s private data feature for sensitive info.

**Data privacy:** The system handles commercial data (inventory, shipments).  No PII of customers is involved, but we’ll secure all data in transit and at rest.  Access to the blockchain will be permissioned; ledger data is not public.

Overall, while there are challenges (sensor noise, API choreography, consortium setup), our mitigations (testing, fallback rules, governance) will keep risks low.  By addressing these risks proactively, the Freshness Assurance system can be reliably deployed across Walmart’s U.S. perishable supply chain (with the architecture easily extendable to other countries’ operations in future).

**Sources:** Walmart’s own sustainability reports and API documentation, industry studies on food-waste reduction, and Walmart’s blockchain traceability initiatives.  (See references for details.)
